### ‚úÖ **Phase 1 : Impl√©mentation de l'Architecture Agentique de Base (LLM & CLI)**

-   **Configuration & Environnement :**
    -   **Gestion des d√©pendances :** Mise √† jour de `pyproject.toml` pour inclure `openai` (client compatible OpenRouter) et `pydantic-settings`. Retrait volontaire de `langchain` pour garder une architecture l√©g√®re et sur-mesure.
    -   **Variables d'environnement :** Cr√©ation de `core/env.py` utilisant `pydantic-settings` pour typer et valider les variables `OPENROUTER_API_KEY` et `VAULT_PATH`. Ajout d'un `.env.example`.

-   **Sch√©mas de Donn√©es (Schemas) :**
    -   **[`schemas/message.py`] :** D√©finition des classes de messages (`Message`, `SystemMessage`, `HumanMessage`, `AIMessage`, `ToolMessage`) avec des m√©thodes `to_dict()` pour s√©rialiser proprement les √©changes vers l'API sans d√©pendre de LangChain.
    -   **[`schemas/event.py`] :** Cr√©ation des mod√®les Pydantic pour le streaming d'√©v√©nements (`ThinkEvent`, `AnswerEvent`, `ToolEvent`, `UsageEvent`, `ErrorEvent`), permettant au client de r√©agir dynamiquement √† chaque √©tape de la r√©flexion du LLM.
    -   **[`schemas/tool.py`] :** Impl√©mentation de la classe `ToolCall` pour repr√©senter et manipuler les appels d'outils demand√©s par le LLM, incluant le parsing des arguments JSON et le formatage des r√©sultats en `ToolMessage`.

-   **Client LLM (OpenRouter) :**
    -   **[`llm/config.py`] :** Configuration du mod√®le par d√©faut (`DEFAULT_MODEL`) pointant vers `google/gemini-2.5-flash` via OpenRouter, avec la logique de calcul des co√ªts (`CostDetails`) bas√©e sur les tokens en entr√©e et en sortie.
    -   **[`llm/client.py`] :** Cr√©ation du `LLMClient` utilisant le SDK `openai`. Impl√©mentation de la m√©thode `stream()` qui g√®re la communication avec l'API, parse les chunks en temps r√©el (texte, r√©flexion, usage), et ex√©cute les appels d'outils de mani√®re *inline*. Le param√®tre `reasoning_effort` a √©t√© conserv√© et int√©gr√© aux param√®tres de l'API.

-   **Architecture Agentique :**
    -   **[`agent/base_agent.py`] :** Cr√©ation de la classe `BaseAgent` qui orchestre la boucle de raisonnement. Impl√©mentation d'une boucle √† deux passes (`_loop`) : un premier appel LLM, la d√©tection et l'ex√©cution des outils, puis un second appel LLM avec les r√©sultats inject√©s dans le contexte. Int√©gration d'une m√©thode `_display` pour le rendu visuel dans le terminal.
    -   **[`prompts/update_prompt.py` & `prompts/search_prompt.py`] :** Cr√©ation des instructions syst√®me (system prompts) minimalistes (placeholders) d√©finissant les r√¥les respectifs des agents de mise √† jour (√©criture/routing) et de recherche (lecture seule).
    -   **[`agent/update_agent.py`] :** Impl√©mentation de l'`UpdateAgent`. Surcharge de la m√©thode `process()` pour charger automatiquement le contexte initial du vault (`overview.md`, `tree.md`, `profile.md`) avant d'y concat√©ner l'input utilisateur et l'√©ventuelle r√©f√©rence d'inbox (`inbox_ref`).
    -   **[`agent/search_agent.py`] :** Impl√©mentation du `SearchAgent` sur le m√™me mod√®le que l'UpdateAgent, mais d√©di√© aux requ√™tes en lecture seule.

-   **Interface Utilisateur (CLI) :**
    -   **[`terminal.py`] :** Cr√©ation du point d'entr√©e interactif en ligne de commande. Mise en place d'une boucle permettant √† l'utilisateur de choisir le mode (`update` ou `search`), d'instancier l'agent correspondant, et d'envoyer des requ√™tes en continu avec un affichage format√© des r√©ponses et des actions d'outils.

### ‚úÖ **Phase 2 : R√©introduction de LangChain, Syst√®me d'Outils et Boucle Agentique Dynamique**

-   **Gestion des D√©pendances & Environnement :**
    -   **R√©introduction strat√©gique de LangChain :** Abandon de l'approche d'introspection customis√©e pour la g√©n√©ration des sch√©mas d'outils. R√©int√©gration de `langchain-core` (et d√©pendances associ√©es) pour exploiter le d√©corateur `@tool`, garantissant une g√©n√©ration de JSON schemas robuste et standardis√©e pour OpenRouter/OpenAI.
    -   **[`pyproject.toml`] :** Ajout des d√©pendances `langchain>=0.3.26,<1.0.0`, `langchain-community==0.3.27`, `langchain-core==0.3.81` et `langchain-openai==0.3.8`. Abaissement de la contrainte Python de `>=3.12` √† `>=3.10` pour assurer la compatibilit√© avec les environnements locaux (`pyenv`) sans casser le conteneur Docker.
    -   **[`knower`] (CLI Bash) :** Ajout de la commande `shell` (`docker compose exec -it core bash`) pour faciliter le workflow de d√©veloppement interactif directement √† l'int√©rieur du conteneur en t√¢che de fond.

-   **Syst√®me d'Outils (Tool Wrapper) :**
    -   **[`tools/tool_base.py`] :** Cr√©ation de la classe `BaseTool` qui agit comme un pont entre le client LLM et LangChain. Utilisation du d√©corateur `@tool` pour encapsuler les fonctions Python. Impl√©mentation de la m√©thode `to_schema()` pour extraire le `model_json_schema()` et de la m√©thode `invoke()`. Ajout d'une propri√©t√© `@property def name` pour permettre au `LLMClient` de r√©soudre l'outil par son nom lors du parsing du stream.
    -   **[`tools/dummy_tools.py`] :** Cr√©ation d'outils factices (`tree` et `read`) retournant des cha√Ænes de caract√®res mock√©es. Ces outils permettent de valider la m√©canique compl√®te de la boucle agentique (LLM -> Tool -> LLM) avant de brancher les v√©ritables interactions avec le syst√®me de fichiers.
    -   **[`agent/vault_tools.py`] :** Suppression du fichier devenu obsol√®te suite √† la cr√©ation du package `tools/`.

-   **Boucle Agentique Dynamique (N-it√©rations) :**
    -   **[`agent/base_agent.py`] :** Refonte majeure de la m√©thode `_loop`. Remplacement de la logique statique √† deux passes par une boucle `while` dynamique. L'agent peut d√©sormais encha√Æner un nombre ind√©fini d'actions (r√©flexion, appel d'outil, analyse du r√©sultat, nouvel appel) jusqu'√† ce qu'il d√©cide de formuler sa r√©ponse finale (absence de `tool_calls`). Ajout d'un garde-fou `max_iterations = 15` pour pr√©venir les boucles infinies.
    -   **[`agent/update_agent.py` & `agent/search_agent.py`] :** Injection des instances `TreeTool` et `ReadTool` dans l'initialisation des agents. Correction de la m√©thode `_load_vault_context` pour utiliser la fonction `read` factice au lieu d'une d√©pendance `mcp_server` non encore impl√©ment√©e, √©vitant ainsi les crashs au d√©marrage.

-   **Fixes, D√©bogage & Ajustements d'Ex√©cution :**
    -   **Affichage des tokens de r√©flexion (Thinking) :** R√©solution d'un bug o√π l'agent semblait "silencieux" malgr√© la consommation de tokens. Mise √† jour de la m√©thode `_display` dans `base_agent.py` pour intercepter les √©v√©nements de type `think` (g√©n√©r√©s par le param√®tre `reasoning_effort`) et les afficher en gris (`\033[90m`). Cela rend le processus de raisonnement du mod√®le visible et facilite grandement le d√©bogage.
    -   **[`terminal.py`] :** R√©solution de l'erreur `ModuleNotFoundError: No module named 'env'` lors de l'ex√©cution directe du script dans le conteneur. Ajout d'une manipulation du `sys.path` (`sys.path.append(...)`) en t√™te de fichier pour forcer la r√©solution des imports absolus depuis la racine du dossier `core/`.
    -   **[`llm/config.py`] :** Changement du mod√®le par d√©faut de `google/gemini-2.5-flash` vers `google/gemini-3-flash-preview`. Le mod√®le 2.5 pr√©sentait des difficult√©s √† formater correctement les appels d'outils (JSON) apr√®s avoir g√©n√©r√© un bloc de r√©flexion textuelle (`<think>`) via OpenRouter, tandis que la version 3 g√®re parfaitement la transition vers le *tool calling*.

### ‚úÖ **Phase 3 : Refonte du Logging Terminal ‚Äî S√©paration Display/Agent et Formatage Propre**

-   **Probl√®me initial et objectif :**
    -   **Constat :** Le terminal affichait un logging d√©gueulasse ‚Äî les tool calls sur une ligne compress√©e avec r√©sultat tronqu√© √† 80 caract√®res, des emojis partout, et le `BaseAgent` √©tait responsable de tout l'affichage via une m√©thode `_display()` interne. L'agent et la pr√©sentation √©taient coupl√©s.
    -   **Objectif :** Extraire toute la logique d'affichage hors de l'agent, obtenir un format de log lisible orient√© debug (`ToolCall ->`, `ToolResult:`, `Tokens:`), et impl√©menter une s√©paration stricte des responsabilit√©s.

-   **Refonte architecturale ‚Äî Agent ‚Üí Generator :**
    -   **[`agent/base_agent.py`] :** Transformation de `run()` et `_loop()` de m√©thodes retournant une `str` en generators (`Generator[dict, None, None]`). La m√©thode `_stream_and_collect()` a √©t√© supprim√©e ‚Äî le streaming se fait d√©sormais directement dans `_loop()` via `yield from self.llm.stream(messages)`. La m√©thode `_display()` et ses helpers ont √©t√© enti√®rement retir√©s. L'agent ne printe plus rien. En cas d'atteinte du `max_iterations`, un event `{"type": "error", "id": "max_iter", ...}` est yielded plut√¥t qu'un print direct. Ajout d'une unique docstring de classe exhaustive rempla√ßant tous les commentaires inline.
    -   **[`agent/search_agent.py`] et [`agent/update_agent.py`] :** `process()` converti en generator avec `yield from self.run(payload)`. Les type hints de retour ont √©t√© retir√©s (implicitement generator).

-   **Fix source ‚Äî Ordre des events `usage` :**
    -   **Probl√®me :** L'event `usage` √©tait yielded par `client.py` au moment o√π il arrivait dans le stream LLM, soit *avant* les events `tool`. Il apparaissait donc dans le terminal entre le message utilisateur et le premier `ToolCall`, ce qui n'avait aucun sens s√©mantique.
    -   **[`llm/client.py`] :** Introduction d'une variable locale `usage_event = None` dans `stream()`. Lors du processing des chunks, si un `UsageEvent` est d√©tect√© via `isinstance(event, UsageEvent)`, il est stock√© au lieu d'√™tre yielded imm√©diatement. Il est yielded en dernier, apr√®s tous les tool events, garantissant que `Tokens:` appara√Æt toujours √† la fin du bloc correspondant. Cette d√©cision de fixer le probl√®me √† la source (dans le client) plut√¥t que dans le display a √©t√© explicitement choisie pour √©viter tout buffering artificiel c√¥t√© affichage.

-   **Cr√©ation de `Display` ‚Äî Logique d'affichage isol√©e :**
    -   **[`agent/display.py`] (nouveau fichier) :** Classe `Display` avec une unique instance variable `agent_started: bool` rempla√ßant l'ancienne variable globale. Le flag est n√©cessaire pour le streaming : les events `answer` arrivent en dizaines de chunks (un par token), et `Agent:` ne doit √™tre print√© qu'une seule fois avant le premier chunk. Chaque requ√™te instancie un nouveau `Display()`, ce qui reset le flag naturellement sans √©tat global.
    -   **Helpers priv√©s :** `_format_tool_args(args_str)` parse le JSON des arguments et les formate en `key="value"` lisibles. `_indent_result(result)` indente chaque ligne du r√©sultat avec 3 espaces pour l'affichage dans le code fence.
    -   **Format final valid√© :**
        ```
        ToolCall -> tree(path=".")
        ToolResult:
        ```
           [contenu indent√©]
        ```
        Tokens: [313 in / 7 out | $0.00018]
        ```

-   **[`terminal.py`] ‚Äî √âpuration compl√®te :**
    -   Toute logique d'affichage retir√©e. Le fichier se r√©duit √† 40 lignes : instanciation de l'agent choisi, boucle `input()` avec `User:` comme prompt (servant simultan√©ment de label et de prompt de saisie, √©vitant tout doublon d'affichage), instanciation d'un `Display()` frais par requ√™te, it√©ration sur `agent.process(user_input)` et dispatch de chaque event √† `display.event(event)`.
    -   Suppression de tous les emojis (`üß†`, `‚úì`, `üîß`, `‚úó`, `‚ùå`, `‚Üí`), du commentaire `sys.path`, et du print redondant du message utilisateur.

-   **Nettoyage transversal :**
    -   **[`llm/client.py`] :** Suppression de l'attribut `last_event_type` jamais utilis√© fonctionnellement. Suppression du commentaire `lazy import to avoid circular`. Retrait de tous les commentaires inline dans `stream()`, `_process_chunk()`, et `_execute_tool()`.
    -   **[`agent/base_agent.py`] :** `from typing import List` √©tendu √† `List, Generator`. Suppression de `_stream_and_collect` comme couche interm√©diaire devenue inutile.

### ‚úÖ **Phase 4 : S√©curisation de la Boucle Agentique et Graceful Degradation**

-   **Architecture & M√©canique de la Boucle Agentique :**
    -   **Clarification du m√©canisme de sortie naturel :** Validation du fait que l'agent n'a pas besoin d'un outil explicite (type `finish()`) pour terminer sa t√¢che. La boucle s'arr√™te organiquement lorsque le LLM d√©cide de g√©n√©rer du texte final (`content`) sans inclure de `tool_calls`.
    -   **S√©paration Planification / Action :** Confirmation que la planification interne du mod√®le (via les tokens de `reasoning` ou de mani√®re latente pour les mod√®les standards) ne d√©clenche pas de sortie pr√©matur√©e. Le mod√®le peut "penser" puis agir dans la m√™me it√©ration sans briser la boucle.

-   **Impl√©mentation du Filet de S√©curit√© (Graceful Degradation) :**
    -   **[`agent/base_agent.py`] :** Refonte de la gestion de la limite d'it√©rations pour √©viter une coupure brutale (crash) et la perte du contexte de travail de l'agent.
    -   **Extraction des constantes :** Ajout de `MAX_ITERATIONS = 25` (limite √©largie pour des t√¢ches complexes de m√©moire) et de `FORCE_FINISH_MESSAGE` (directive stricte ordonnant au mod√®le de r√©sumer son travail et de s'arr√™ter) au niveau du module.
    -   **Conservation de l'√©tat :** Modification de `__init__` pour stocker `self.model`, `self.system_prompt` et `self.tools` directement sur l'instance de l'agent. Ces r√©f√©rences sont n√©cessaires pour reconstruire un client LLM de secours.
    -   **Cr√©ation de la m√©thode `_force_finish` :** Impl√©mentation d'un chemin d'ex√©cution distinct appel√© √† la fin du `while` si la limite est atteinte.
    -   **Garantie structurelle de sortie :** Dans `_force_finish`, instanciation d'un nouveau `LLMClient` (`final_llm`) en lui passant explicitement `tools=[]`. Cette absence d'outils garantit m√©caniquement (au niveau de l'API) que le mod√®le ne pourra pas tenter de nouveaux appels et sera forc√© de produire une r√©ponse textuelle de cl√¥ture.
    -   **Tra√ßabilit√© et Debugging :** Ajout d'un √©v√©nement `yield {"type": "error", "id": "max_iterations", ...}` au d√©clenchement du `_force_finish`. Bien que l'arr√™t soit g√©r√© proprement, l'utilisation du type `error` (d√©fini dans `schemas/event.py`) permet au syst√®me d'affichage (`display.py`) de signaler visuellement l'anomalie, atteindre 25 it√©rations n'√©tant pas un comportement nominal pour l'agent.

### ‚úÖ **Phase 5 : Correction du Reasoning OpenRouter et Fix du Streaming de Transition**

-   **Configuration du Reasoning (OpenRouter API) :**
    -   **Alignement avec le sch√©ma OpenRouter :** Le mod√®le s'arr√™tait apr√®s avoir "pens√©" sans ex√©cuter d'actions car le param√®tre `reasoning_effort` √©tait envoy√© en top-level (format natif OpenAI) au lieu d'√™tre encapsul√© dans `extra_body`, ce qui entra√Ænait son ignorance par OpenRouter. De plus, la valeur `"low"` bridait la capacit√© du mod√®le √† planifier des appels d'outils.
    -   **[`llm/client.py`] :** Simplification de l'initialisation du `LLMClient` pour accepter une simple string `reasoning` (`"low"`, `"medium"`, `"high"`, ou `None`). Modification de la m√©thode `stream()` pour construire et injecter dynamiquement le dictionnaire `stream_params["extra_body"] = {"reasoning": {"effort": self.reasoning}}` uniquement si le param√®tre est d√©fini.
    -   **[`agent/base_agent.py`] :** Mise √† jour de l'instanciation du `LLMClient` (dans `__init__` et dans le fallback `_force_finish`) pour passer explicitement `reasoning="high"`. Cela garantit que l'agent dispose du budget de tokens n√©cessaire pour analyser le contexte et orchestrer ses actions.

-   **R√©solution du Bug de Transition (Streaming) :**
    -   **Pr√©vention de la perte de donn√©es (Data Loss) :** Identification et correction d'un bug latent critique dans le traitement des chunks de streaming. Lors de la transition exacte entre la fin de la r√©flexion et le d√©but d'un appel d'outil, le code retournait imm√©diatement la balise `</think>`, ignorant le reste du chunk. Cela entra√Ænait la perte du premier fragment de l'appel d'outil (souvent le nom de la fonction), causant des erreurs silencieuses ou des √©checs de type `Tool '' not found`.
    -   **[`llm/client.py`] :** Refonte de la logique dans `_process_chunk()`. Au lieu d'un `return` anticip√© lors de la d√©tection de la fin du thinking (`is_thinking_started = False`), l'√©v√©nement est d√©sormais stock√© dans une variable locale (`end_think_event`). Le code utilise ensuite un *fall-through* pour descendre dans les blocs d'√©valuation `content` et `tool_calls`. Les fragments d'outils du chunk de transition sont ainsi accumul√©s par effet de bord dans `self.tool_calls`, et l'√©v√©nement `</think>` est retourn√© proprement √† la fin de la fonction.

-   **Validation de la Boucle Agentique :**
    -   **Ex√©cution N-it√©rations fonctionnelle :** Test et validation d'une boucle agentique compl√®te. Le mod√®le est d√©sormais capable d'encha√Æner de multiples it√©rations (ex: 4 passes) de mani√®re autonome : il g√©n√®re des blocs de r√©flexion (`<think>`), d√©clenche un ou plusieurs outils simultan√©ment (ex: `tree` puis de multiples `read`), analyse les retours factices, et d√©cide naturellement de sortir de la boucle pour formuler sa r√©ponse textuelle finale.

### ‚úÖ **Phase 6 : Impl√©mentation du Syst√®me d'Outils (Tools) et R√©solution des Chemins du Vault**

-   **Centralisation et D√©finition du Registre d'Outils :**
    -   **Cr√©ation du module unifi√© :** Remplacement de l'ancien syst√®me temporaire par un registre complet impl√©mentant les 9 outils d√©finis dans la sp√©cification du MVP (`tree`, `read`, `search`, `write`, `edit`, `append`, `move`, `delete`, `concat`).
    -   **[`tools/tools.py`] :** Cr√©ation du fichier central. Les outils d'√©criture, de recherche s√©mantique et de manipulation de fichiers (`write`, `edit`, `append`, `move`, `delete`, `search`, `concat`) ont √©t√© initialis√©s sous forme de *dummy functions* retournant des cha√Ænes format√©es. Cela permet de valider la logique de *tool calling* du LLM avant de brancher les v√©ritables actions syst√®me.
    -   **S√©gr√©gation des acc√®s (RBAC) :** D√©finition de deux listes export√©es distinctes : `SEARCH_TOOLS` (lecture seule : `tree`, `read`, `search`, `concat`) et `UPDATE_TOOLS` (acc√®s complet, sans `concat`).
    -   **Nettoyage :** Suppression d√©finitive de l'ancien fichier `tools/dummy_tools.py`.

-   **Impl√©mentation R√©elle des Outils de Lecture et Navigation :**
    -   **[`tools/tools.py` - `read`] :** Transformation du *dummy* en v√©ritable impl√©mentation lisant le syst√®me de fichiers. Ajout de la logique de budget de tokens via les param√®tres `head` et `tail` (approximation √† 4 caract√®res par token) pour tronquer intelligemment les longs fichiers. Impl√©mentation du formatage automatique des retours : chaque ligne est pr√©fix√©e par son num√©ro absolu (`N  | content`), et le tout est encapsul√© dans un bloc de code Markdown avec le chemin du fichier en en-t√™te.
    -   **[`tools/tools.py` - `tree`] :** C√¢blage de l'outil sur l'impl√©mentation r√©elle existante (`core/functions/tree`), permettant √† l'agent de scanner dynamiquement l'arborescence du vault avec le d√©compte des tokens et les timestamps.

-   **R√©solution Robuste des Chemins (Path Resolution) :**
    -   **[`tools/tools.py` - `_resolve_path`] :** Cr√©ation d'un helper critique pour normaliser les chemins g√©n√©r√©s par le LLM. Il g√®re les noms de fichiers simples (`overview.md`), les chemins pr√©fix√©s (`vault/projects/...`), et les alias de racine (`.`, `./`, `vault/`).
    -   **Support des environnements locaux :** Ajout de `.resolve()` sur `Path(env.VAULT_PATH)` pour convertir dynamiquement les chemins relatifs du `.env` (ex: `../vault`) en chemins absolus bas√©s sur le contexte d'ex√©cution (`cwd`). Cela corrige l'erreur `Path does not exist: /vault` rencontr√©e en local.
    -   **Fix du scope de `tree` :** Application de `_resolve_path` √† l'outil `tree`. Cela corrige un bug majeur o√π l'appel `tree(".")` scannait le r√©pertoire du code source Python au lieu du vault, ce qui entra√Ænait des crashs de d√©codage UTF-8 en tentant de lire les m√©tadonn√©es de fichiers binaires compil√©s (`.pyc`).

-   **Mise √† jour et Simplification des Agents :**
    -   **[`agent/search_agent.py` & `agent/update_agent.py`] :** Injection des nouvelles listes `SEARCH_TOOLS` et `UPDATE_TOOLS` dans l'initialisation des agents respectifs, garantissant que l'agent de recherche ne peut physiquement pas alt√©rer le vault.
    -   **Refactoring de `_load_vault_context` :** Simplification drastique de la m√©thode. Puisque le nouvel outil `read` retourne d√©sormais le contenu pr√©-format√© avec des blocs Markdown et le nom du fichier, les ajouts manuels d'en-t√™tes (`## overview.md\n`) ont √©t√© retir√©s. Les appels aux fichiers de contexte (`overview.md`, `tree.md`, `profile.md`) sont maintenant de simples concat√©nations directes. Le *lazy import* de la fonction `read` a √©galement √©t√© remont√© au niveau du module.

### ‚úÖ **Phase 7 : Modularisation des Prompts Syst√®me & Finalisation du Search Agent**

-   **Architecture des Prompts (DRY & Modularit√©) :**
    -   **Strat√©gie de factorisation :** Adoption d'une approche modulaire pour la gestion des *system prompts*. Au lieu de dupliquer les descriptions de l'environnement et des outils dans chaque agent, ces blocs textuels sont extraits dans des fichiers de constantes partag√©es. Cela garantit une coh√©rence absolue entre l'`UpdateAgent` et le `SearchAgent` et facilite la maintenance future.
    -   **[`prompts/env_prompt.py`] :** Cr√©ation de ce module pour stocker les constantes contextuelles communes :
        -   `ENVIRONMENT_PROMPT` : Description exhaustive de l'architecture du vault (r√¥le de chaque fichier, indexation QMD vs lecture directe).
        -   `AGENTIC_MODEL_PROMPT` : D√©finition de la boucle autonome (raisonnement, appels d'outils, condition d'arr√™t).
        -   `INITIAL_CONTEXT_PROMPT` : Explication des trois fichiers charg√©s au d√©marrage (`overview`, `tree`, `profile`) et comment s'en servir pour s'orienter sans co√ªt.
    -   **[`prompts/tools_prompt.py`] :** Centralisation des descriptions strat√©giques des outils (le *quand* et le *comment*, pas la signature technique). Impl√©mentation des constantes pour les outils de lecture et navigation :
        -   `SEARCH_TOOL_PROMPT` : Strat√©gies `fast` (BM25) vs `deep` (s√©mantique), usage des scopes.
        -   `READ_TOOL_PROMPT` : Gestion des gros fichiers (`head`/`tail`) et lecture de dossiers.
        -   `TREE_TOOL_PROMPT` : Usage pour l'exploration structurelle fine.
        -   `CONCAT_TOOL_PROMPT` : Instructions pour l'assemblage final de la r√©ponse (sp√©cifique au Search, mais stock√© ici pour coh√©rence).

-   **Finalisation du Prompt Search Agent :**
    -   **[`prompts/search_prompt.py`] :** R√©√©criture compl√®te du fichier pour assembler dynamiquement le prompt final via des f-strings.
    -   **Structure composite :** Le prompt combine d√©sormais les constantes import√©es (`env_prompt`, `tools_prompt`) avec les sections sp√©cifiques √† l'agent de recherche :
        -   `<identity>` : D√©finition stricte du r√¥le *read-only* et de l'objectif "What does the user need to know?".
        -   `<search-strategy>` : Documentation des patterns de recherche multi-pass adapt√©s au type de question (temporelle, statut, historique, cross-projet, vague).
        -   `<rules>` : Invariants absolus (jamais √©crire, jamais inventer, jamais halluciner des paths).
        -   `<output>` : Format de sortie strict en deux parties (Overview r√©dig√©e + Fichiers concat√©n√©s).

### ‚úÖ **Phase 8 : Standardisation des Prompts Syst√®me & Impl√©mentation de l'Update Agent**

-   **Refonte Qualitative du Search Prompt :**
-   **Alignement sur les standards de qualit√© :** R√©√©criture compl√®te de `search_prompt.py` pour abandonner le format "manuel proc√©dural" (listes √† puces, sous-cat√©gories rigides) au profit d'une prose fluide et directive. Adoption du pattern "Bold Lead-in + Paragraphe" pour transmettre le *mindset* de l'agent plut√¥t qu'une simple suite d'instructions.
-   **[`prompts/search_prompt.py`] :**
    -   **`<identity>` :** Resserr√©e √† l'essentiel (3 lignes), suppression des justifications d√©fensives ("this is not a limitation").
    -   **`<search-strategy>` :** Transformation radicale. Les 5 cat√©gories de questions (temporelle, statut, etc.) sont tiss√©es organiquement dans le texte. L'accent est mis sur le raisonnement initial (utiliser `overview` et `tree` avant tout outil) et l'it√©ration (ne pas s'arr√™ter √† une recherche infructueuse).
    -   **`<rules>` :** Condensation des r√®gles absolues. Suppression des explications √©videntes pour un LLM ("Even if you think a file has a typo...").

-   **Extension du Syst√®me de Prompts (Outils d'√âcriture) :**
-   **[`prompts/tools_prompt.py`] :** Ajout des 5 constantes manquantes pour les outils de modification, suivant le m√™me standard de qualit√© (instructions strat√©giques sur le *quand* et le *comment*, pas de d√©tails techniques).
    -   `WRITE_TOOL_PROMPT` : Distinction claire entre cr√©ation/r√©√©criture compl√®te et modification partielle.
    -   `EDIT_TOOL_PROMPT` : Insistance sur la pr√©condition de lecture (`read` obligatoire avant `edit`) et l'unicit√© du contexte de remplacement.
    -   `APPEND_TOOL_PROMPT` : Explication du workflow "zero-read" pour les changelogs et tasks (insertion aveugle en haut ou en bas).
    -   `MOVE_TOOL_PROMPT` : Cas d'usage pour le routing et la correction d'erreurs.
    -   `DELETE_TOOL_PROMPT` : Usage principal pour le nettoyage de l'inbox apr√®s r√©solution.

-   **Impl√©mentation du Prompt Update Agent :**
-   **[`prompts/update_prompt.py`] :** Cr√©ation du prompt syst√®me complet pour l'agent d'√©criture, rempla√ßant le placeholder existant.
    -   **Architecture Modulaire :** Assemblage dynamique via f-strings incluant `env_prompt`, `agentic_model`, `initial_context` et les 8 outils (lecture + √©criture).
    -   **`<identity>` :** D√©finition du r√¥le de "sole writer" et de la question directrice "Where does this information belong?".
    -   **`<update-strategy>` :** Directives de haut niveau sur le routing (signal fort vs ambigu√Øt√©), la gestion de l'`inbox_ref` (priorit√© absolue), et la cr√©ation de dossiers inbox avec `review.md` en cas de doute.
    -   **`<rules>` :** Interdictions strictes : ne jamais toucher au frontmatter (g√©r√© par le background job), ne jamais r√©g√©n√©rer `tree.md`, et ne jamais terminer sans logger dans `changelog.md`.