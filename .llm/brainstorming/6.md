# Checkpoint Brainstorm — Project Manager / Knowledge Agent
*Suite de la session du 22 fév 2026 — Session 6*

---

## Ce qui s'est passé avant cette session

Les sessions 1 à 5 ont abouti à la définition complète du MVP.
Le MVP est tranché, documenté, et prêt à être implémenté.

Ce document ne parle pas du MVP. Il stocke tout ce qui a été
identifié, discuté, et délibérément mis de côté pendant les sessions précédentes.
Ces features ne sont pas abandonnées — elles sont en attente.
Certaines sont presque prêtes à implémenter, d'autres nécessitent
encore une session de brainstorming dédiée avant de pouvoir être attaquées.

---

## Architecture des agents

### Séparation orchestrateur / worker

Le MVP fait tourner un seul modèle qui fait tout — raisonnement et génération
de contenu. La feature post-MVP, c'est la séparation en deux tiers distincts.

L'orchestrateur tourne sur un modèle puissant — Claude Opus ou équivalent.
Sa tâche : compréhension sémantique profonde, détection de contradictions,
routing complexe, décisions qui impactent la cohérence globale de l'arborescence.
Il génère très peu de texte long. Son output, ce sont des décisions
et des instructions vers le worker.

Le worker tourne sur un modèle cheap et rapide — Gemini Flash ou équivalent.
Sa tâche : mécanique d'exécution. Écrire une entrée de changelog,
mettre à jour une section de state.md, reformuler un bloc de tasks.md.
Ces tâches ne demandent pas de raisonnement sur la cohérence globale du vault.
Elles demandent de bien écrire un bloc de texte précis dans un format connu.

La règle de dispatch : tout ce qui est opération filesystem pure
(move, delete, read) est exécuté directement par l'orchestrateur.
Tout ce qui nécessite de la génération de contenu markdown
est délégué au worker sous forme d'une micro-tâche avec son contexte.

Le worker doit recevoir l'intégralité du contexte disponible —
jamais un contexte appauvri. Il reçoit l'input original de l'utilisateur,
les fichiers joints, et les fichiers que l'orchestrateur a lus
pendant sa phase de raisonnement (state.md du projet, head du changelog,
tasks.md si pertinent). Un worker avec un contexte appauvri produit
des entrées génériques et déconnectées du ton et du vocabulaire existants dans le vault.
Et une mémoire remplie de contenu générique, c'est exactement le problème
que tout ce système est censé résoudre.

---

## Notifications externes et inbox reply

### Canal de notification externe

Le MVP gère les notifications inbox uniquement dans l'interface web.
La feature post-MVP, c'est un canal de notification externe —
Discord ou Telegram, selon ce qui est le plus simple à brancher.

Quand l'agent crée un item dans l'inbox, il envoie une notification
sur le canal configuré. Cette notification contient le contenu du review.md
de l'item — le raisonnement de l'agent et sa question — ainsi que
les fichiers d'input originaux en pièce jointe si c'est pertinent.

### Mécanisme de reply capté depuis le canal externe

C'est la partie la plus complexe de cette feature et elle n'a pas encore
été complètement tranchée techniquement.

L'objectif : quand l'utilisateur reçoit la notification sur Discord ou Telegram,
il peut répondre directement depuis ce canal, sans ouvrir l'interface.
Sa réponse est captée automatiquement par le système et envoyée
à la route `update` avec la metadata `inbox_ref` correspondante.
L'agent de maintenance récupère le folder inbox, traite le routing
avec la réponse en contexte, route les fichiers, supprime le folder,
logue dans le changelog global.

Les mécanismes de capture non encore tranchés :
un webhook Discord lié à un bot, le parsing d'un reply à un email généré
par le système, ou un endpoint HTTP simple exposé pour recevoir la réponse.

### Loop bidirectionnel complet

Ce qui fait la valeur de cette feature, c'est le loop complet :
notification push vers l'utilisateur depuis n'importe où,
réponse de l'utilisateur depuis ce même canal,
traitement automatique, fermeture de la boucle.

Sans ce return path, l'inbox devient un silo passif que l'utilisateur
doit aller consulter manuellement dans l'interface, et l'intérêt s'effondre.
La notification existe précisément pour éviter que l'utilisateur
ait à penser à vérifier s'il y a quelque chose en attente.

Si après la réponse l'ambiguïté subsiste, l'agent met à jour le review.md,
renvoie une nouvelle notification sur le même canal.
Le folder reste ouvert, le thread continue.

---

## Tools des agents

### head/tail sur le read tool

Le read tool du MVP lit toujours un fichier complet.
La feature post-MVP : deux paramètres optionnels `head: N` et `tail: N`,
où N est exprimé en tokens.

`read(path, head: 2000)` retourne les 2000 premiers tokens du fichier.
`read(path, tail: 2000)` retourne les 2000 derniers.
Sans paramètre, le comportement reste le read complet.

L'utilité principale concerne les changelogs.
Puisqu'ils sont newest-first (append top), `head: 2000` sur un changelog
retourne les entrées les plus récentes — exactement ce que l'agent veut
voir pour calibrer une nouvelle entrée sans charger
potentiellement 80 000 tokens d'historique.

La décision de faire un read partiel est informée par tree.md :
l'agent voit que le changelog fait 45 000 tokens, il sait qu'il n'a pas
besoin de tout lire, il fait un `head: 2000` pour avoir le contexte récent
et il append directement. Économie massive de tokens sur les gros changelogs.

### Code execution tool

Plutôt que d'exposer des tools individuels, on expose un seul tool
d'exécution de code. L'agent écrit un script Python, le service l'exécute
dans un environnement contrôlé qui a accès aux fonctions du vault
(read, search, write, tree), et retourne le résultat en markdown.

Ce que ça change concrètement : l'agent peut combiner plusieurs opérations
en un seul appel. Un `tree` suivi d'un `search` suivi de deux `read` ciblés
devient un script qui fait les quatre en séquence et retourne un résultat assemblé.
Moins d'allers-retours entre l'agent et le service, moins de tokens
de coordination, plus de précision sur les opérations complexes.

Ce n'est pas une refonte architecturale — le modèle mental de l'agent
ne change pas, seule la couche d'exécution change. C'est donc
une migration possible sans casser ce qui existe, quand le besoin
de performance se fait sentir concrètement.

---

## Search

### Scopes cross-cutting

Le MVP permet de restreindre une search à un projet spécifique
via `scope: "project:[nom]"`. La feature post-MVP, ce sont
les scopes qui traversent tous les projets en ciblant un type de fichier.

`scope: "all-states"` cherche dans tous les `projects/*/state.md`.
`scope: "all-changelogs"` cherche dans tous les `projects/*/changelog.md`
plus le `changelog.md` global.
`scope: "all-tasks"` cherche dans tous les `projects/*/tasks.md`
plus le `tasks.md` global.
`scope: "all-buckets"` cherche dans tous les `projects/*/bucket/*`
plus le `bucket/` global.
`scope: "all-descriptions"` cherche dans tous les `projects/*/description.md`.

Ces scopes résolvent un problème concret : quand la question est cross-projet
et porte sur un type d'information spécifique, l'agent n'a pas à naviguer
projet par projet manuellement.
"Quels projets sont bloqués ?" → search sur "bloqué" avec `scope: "all-states"`.
"Qu'est-ce que j'avais décidé sur l'architecture de paiement ?" →
search sémantique avec `scope: "all-changelogs"`.
Résultats précis, navigation manuelle évitée.

### Filtrage par date

Deux paramètres optionnels ajoutés au search tool existant :
`date_from` et `date_to`.

Ces paramètres fonctionnent comme des filtres appliqués avant la recherche textuelle.
Sur les changelogs, QMD filtre sur les H1 de date.
Sur les fichiers bucket et les autres fichiers indexés,
il filtre sur les champs `created` et `updated` du frontmatter YAML.
Ensuite seulement, il applique BM25 ou le pipeline complet sur le sous-ensemble filtré.

Ce qui est puissant, c'est que ça se compose naturellement avec le scope et le mode.
"Toutes les décisions prises sur startup-x en juin" devient
`search("[décision]", mode: "fast", scope: "project:startup-x",
date_from: "2025-06-01", date_to: "2025-06-30")`.
"Tout ce qui s'est passé cette semaine" devient
`search("*", date_from: "7 days ago")` en full vault.

### Politique d'usage fast vs deep

Le MVP laisse l'agent décider librement selon la nature de la requête.
La feature post-MVP, c'est des heuristiques concrètes et explicites
qui guident ce choix — soit sous forme de règles dans le system prompt,
soit via un mécanisme de décision dynamique formalisé.

Fast pour : noms propres, dates, identifiants, termes exacts, tags comme `[décision]`.
Deep pour : questions sémantiques, formulations vagues, recherches conceptuelles,
"ce truc qu'on avait décidé sur l'architecture de paiement."
La question non tranchée : est-ce que l'agent décide toujours dynamiquement,
ou est-ce qu'on default sur deep pour tout et on affine à l'usage ?

---

## Streaming et visibilité

### WebSocket réel pour les actions de l'agent

Le MVP simule les étapes de l'agent dans la vue activité de l'interface.
La feature post-MVP, c'est un flux WebSocket réel qui push les actions
de l'agent au fur et à mesure qu'elles se produisent.

L'agent émet des events à chaque action — `reading: overview.md`,
`searching: startup-x changelog`, `writing: state.md`, etc.
L'interface reçoit ces events en temps réel et les affiche
dans la vue activité au rythme réel du raisonnement de l'agent.

Ce n'est pas juste du polish — c'est ce qui permet à l'utilisateur
de voir que le système travaille vraiment, pas qu'il simule.
C'est le moment où la confiance dans le système se construit.

### Visibilité sur l'évolution de la mémoire

Question ouverte depuis la session 1, jamais tranchée.
L'utilisateur veut pouvoir voir comment sa knowledge base évolue.
Si l'agent fait des modifications en continu, comment l'utilisateur
garde le contrôle et la confiance ?

Trois options identifiées, non mutuellement exclusives :

Git history : chaque modification du file tree est commitée automatiquement.
L'utilisateur peut ouvrir le repo et voir les diffs.
Simple, gratuit, universel.

Meta-log : un fichier `memory-log.md` qui trace les modifications
effectuées par les agents — quoi a changé, quand, pourquoi.
Lisible dans l'interface.

Interface dédiée : un feed dans l'interface qui montre les changements récents
avec possibilité de voir les diffs et de revenir en arrière.

Cette question reste entièrement ouverte — à traiter en session dédiée.

---

## Infrastructure et déploiement

### Cloud MCP avec authentification

Le MVP tourne en local uniquement.
La feature post-MVP, c'est d'exposer le même MCP server sur une URL publique
avec une couche d'authentification devant.

Le code du server ne change pas entre les deux modes —
c'est une question de transport et d'URL, pas d'architecture.
En local, le server tourne sur localhost.
En cloud, le même server est exposé sur une URL publique avec auth devant.

Ce qui est puissant : la mémoire est une, les portes d'entrée sont multiples.
Claude Code en local appelle le MCP local.
Un agent custom sur un serveur distant appelle le MCP cloud.
Les deux lisent et écrivent dans le même vault, via la même interface,
avec les mêmes deux opérations.

### Sync git ou rsync du vault

Le MVP stocke le vault localement sans mécanisme de sync.
La feature post-MVP, c'est de permettre à l'utilisateur de syncer son vault
vers un repo privé ou un stockage cloud pour la persistance et la portabilité.

Le service lui-même ne gère pas le sync — c'est de l'infrastructure
optionnelle en dehors du produit. La source de vérité reste les fichiers locaux.
Même principe qu'Obsidian : les fichiers sont là, la sync est une couche externe.

---

## Interface

### Édition des fichiers depuis l'interface

Le MVP affiche les fichiers en read-only avec Streamdown ou Plate.js.
La feature post-MVP, c'est de rendre ces fichiers éditables directement
depuis la zone centrale de l'interface. L'utilisateur peut modifier
un changelog, corriger une tâche, mettre à jour un state sans passer
par le chat input ou par un éditeur externe.

Plate.js est le candidat naturel pour ça — il est conçu pour être
à la fois un renderer et un éditeur riche.

### Support Windows et cross-platform

Le MVP est macOS uniquement — volume Docker monté en local,
file watcher adapté à Unix.
Le support Windows est une feature post-MVP qui nécessite
d'adapter la couche de file watching et potentiellement
la gestion des paths dans le vault.

### Mobile

Pas encore discuté en détail. L'interface web est responsive par nature
si elle est construite avec Tailwind, mais une expérience mobile native
ou optimisée est une feature post-MVP à part entière.
Le cas d'usage mobile le plus évident : consulter sa mémoire et envoyer
des updates rapides depuis son téléphone, notamment des vocaux transcrits.

---

## Intégrations

### MCP skills et connectivité externe

Le vault doit être exportable et pluggable dans d'autres outils que le service lui-même.
La vision : n'importe quel agent compatible MCP peut appeler le service
pour lire du contexte projet ou y déposer de l'information.

Questions non encore tranchées :
comment un skill MCP expose le contexte projet à ChatGPT ou Claude,
si c'est un export markdown statique ou une API dynamique,
et comment on gère l'authentification si le vault est exposé via MCP
sur une URL publique.

---

## Flow end-to-end du maintenance agent

Jamais complètement tracé en session de brainstorming malgré
d'être identifié comme prioritaire dans les sessions 1 à 5.

Ce qui reste à dérouler de façon exhaustive :
quel est l'arbre de décision exact quand une requête arrive avec du texte
et des fichiers joints, dans quel ordre exact l'agent lit les fichiers,
prend ses décisions, et exécute ses actions, comment il décide si une
information contredit quelque chose qui existe déjà et comment il utilise
le search tool pour le vérifier avant d'écrire, dans quel ordre les fichiers
sont mis à jour, comment l'overview est régénérée, et quels sont les cas limites
— information contradictoire, projet inexistant référencé, fichier trop gros
pour être chargé d'un coup, routing ambigu entre plusieurs projets existants.

Ce tracé est une session de brainstorming à part entière.
Il débloque l'implémentation propre du system prompt
et de la logique de décision de l'agent de maintenance.