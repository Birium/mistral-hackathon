# Checkpoint Brainstorm — Project Manager / Knowledge Agent
*Suite de la session du 22 fév 2026 — À reprendre ici*

---

## Ce qui a changé par rapport à la session précédente

Ce document est la suite directe du premier brainstorming. Tout ce qui était tranché reste tranché. Ce document capture uniquement les évolutions, nouveaux éléments, et décisions prises dans cette session. Les deux documents ensemble forment la spec complète.

---

## Décisions prises dans cette session

### 1. Voice-first : éliminé du scope

Ce n'est pas une feature, c'est de la connectivité. Tout fichier audio ou vocal passe par un layer de processing qui le convertit en texte avant que le système le touche. Des processeurs existent déjà pour ça. Ce n'est pas un problème à résoudre dans ce brainstorming. À l'entrée du système, tout est toujours du texte ou des fichiers structurés — à l'exception des images, voir point suivant.

---

### 2. Le layer de processing : ce qui se transforme et ce qui ne se transforme pas

Quand l'utilisateur envoie de l'information au système, cette information peut être du texte brut, des PDFs, des fichiers audio, des CSVs, des images, ou n'importe quelle combinaison. Il y a toujours un layer de processing en amont de l'agent, mais ce layer ne transforme pas tout.

Ce qui se convertit en texte avant d'arriver à l'agent : PDFs, fichiers audio et transcriptions, CSVs, documents texte de tout format.

Ce qui ne se convertit pas : les images. Les images restent en tant qu'images. Elles peuvent être chargées directement dans la session de chat et l'agent peut les lire visuellement. Ce n'est pas un problème — les modèles savent faire ça. Il ne faut pas les dégrader en descriptions texte quand la version originale est plus riche.

La requête est toujours traitée en entier, pas fichier par fichier. Si l'utilisateur envoie 3 fichiers et un message texte, l'agent traite tout ça comme une seule requête et prend toutes les décisions de routing en une passe.

---

### 3. Overview : jamais tronquée, jamais

L'overview affiche toujours tous les projets, sans exception, peu importe le nombre. 45 projets, 80 projets — tout est dedans. La discipline de format (une ligne par projet, statut synthétique) maintient la taille gérable, pas la troncature. Tronquer l'overview, c'est laisser mourir de l'information — exactement le problème qu'on résout.

---

### 4. Les deux agents : maintenance et search, rien d'autre

Il y a exactement deux agents dans le système. Pas de sous-agents, pas d'orchestrateur séparé, pas d'architecture de delegation avec passage de contexte.

L'agent de maintenance lit et écrit. Son travail : maintenir la cohérence de l'arborescence. Il reçoit une requête, il navigue le file tree avec ses tools, il prend ses décisions, il agit.

L'agent de search lit uniquement. Son travail : traverser l'arborescence, connecter des informations, construire du contexte, répondre à des questions.

Les deux agents opèrent sur le même file tree avec les mêmes tools de lecture. Seul l'agent de maintenance a les tools d'écriture.

---

### 5. Les tools des agents

Les agents ont des tools de base pour interagir avec le file system. Ces tools sont simples et directs — l'agent les utilise comme il le juge nécessaire selon la situation.

**Read** : lire un fichier. Peut lire le contenu complet ou uniquement le frontmatter sans charger le contenu. L'agent décide.

**Edit** : modifier une partie d'un fichier existant. Couvre l'append dans un changelog, le déplacement d'une tâche d'une section à une autre, la mise à jour d'une section de state.md. L'agent lit d'abord si nécessaire, puis édite.

**Write** : créer un nouveau fichier ou réécrire un fichier entier from scratch. Couvre la création d'un item bucket, la réécriture d'une description après un pivot, la régénération de l'overview.

**Delete** : supprimer un fichier. Pour vider l'inbox après traitement, supprimer un fichier bucket obsolète.

**Tree** : voir section dédiée ci-dessous.

Il n'y a pas de distinction architecturale forcée entre edit chirurgical et réécriture complète. L'agent décide lui-même. Pour un append changelog, il peut Edit directement sans lire. Pour les tâches, il Read puis Edit. Pour une description, il Read, raisonne, puis Write. Si lire et réécrire un fichier coûte des tokens — c'est acceptable. C'est un prototype.

---

### 6. Architecture des buckets : global + par projet, sans liens croisés

Deux niveaux de bucket, sans aucune metadata de liaison entre eux.

Le bucket global est le parking. Les fichiers orphelins, ceux pas encore rattachés à un projet, ou ceux trop généraux pour appartenir à un projet spécifique. Pas de frontmatter `projects:`, pas de liens implicites. Propre.

Chaque projet a son propre bucket. Les fichiers qui appartiennent clairement à un projet vont directement dans le bucket du projet, sans passer par le global.

Des fonctions permettent de déplacer un fichier d'un bucket à un autre, ou de le dupliquer dans plusieurs buckets. Si un fichier concerne deux projets, on le duplique dans les deux. Deux copies d'un fichier markdown, c'est infiniment plus simple à maintenir qu'un système de liens croisés.

Ce qui a été éliminé : le frontmatter `projects:` sur les fichiers du bucket global, et le fichier `references.md` dans chaque projet. La position du fichier dans le file tree EST l'information. Pas besoin de le déclarer en plus dans le contenu.

---

### 7. Le tool Tree : navigation token-aware du file system

C'est l'un des tools les plus importants du système. Les deux agents l'ont. Sans lui, un agent navigue à l'aveugle et peut ouvrir un dossier de 80k tokens et saturer sa context window sans l'avoir anticipé.

Le tree prend trois paramètres. `path` pour définir à partir d'où afficher — `vault/` pour tout, `vault/projects/startup-x/` pour un projet spécifique. `depth` pour contrôler combien de niveaux on descend — `1` pour le contenu immédiat uniquement, `null` pour tout. Et `metadata` en booléen pour inclure ou non les champs frontmatter pertinents au-delà des informations de base.

Pour chaque fichier, le tree affiche le nom, le nombre de tokens, et la date de dernière modification. Pour chaque dossier, il affiche le total de tokens agrégés de tout son contenu. Quand la profondeur maximale est atteinte et qu'un sous-dossier n'est pas déplié, il affiche un résumé du type `... 6 files, 1 folder` avec le total de tokens — l'agent sait qu'il y a du contenu et combien ça pèse, sans le détail.

Exemple de sortie pour `tree("vault/", depth=2)` :

```
vault/                                    [52.4k tokens]
├── overview.md                    340 tk · 2h ago
├── profile.md                     280 tk · 5d ago
├── tasks.md                       520 tk · 1d ago
├── changelog.md                 1,200 tk · 3h ago
├── inbox/                               [890 tokens]
│   └── vocal-2025-07-14.md        890 tk · 6h ago
├── bucket/                            [8.2k tokens]
│   └── ... 6 files
└── projects/                         [41.3k tokens]
    ├── startup-x/                    [18.3k tokens]
    │   └── ... 5 files, 1 folder
    └── appart-search/                [11.2k tokens]
        └── ... 5 files, 1 folder
```

Exemple avec `metadata=true` sur un scope précis :

```
startup-x/bucket/                     [12.1k tokens]
├── vocal-meeting.md           2,100 tk · 2d ago
│   type: vocal · topics: client, deadline
├── email-specs-v2.md          8,400 tk · 5d ago
│   type: email · topics: specs, scope-change
└── notes-brainstorm.md        1,600 tk · 1d ago
    type: note · topics: architecture
```

Avec ce tool, l'agent prend 80% de ses décisions de navigation sans ouvrir un seul fichier. Il sait ce qu'il va trouver avant d'y aller.

---

### 8. Le système de token-awareness : background job sur chaque save

Les tokens de chaque fichier sont stockés dans son frontmatter YAML sous le champ `tokens`. Ce champ est mis à jour automatiquement par un background job — pas un agent, pas un LLM, un processus programmatique simple et déterministe.

À chaque fois qu'un fichier est écrit ou modifié, le background job se déclenche. Il calcule le nombre de tokens avec `Math.ceil(text.length / 4)` — approximation suffisante, rapide, sans dépendance externe. Il met à jour le champ `updated` avec le timestamp courant.

Ce n'est pas un job périodique, pas un full-scan. C'est event-driven : fichier écrit → metadata mise à jour. Immédiat, sans overhead.

L'agent ne pense jamais à mettre à jour les metadata après une écriture. C'est de la plomberie, pas du raisonnement. Le background job s'en occupe systématiquement.

Le tree tool lit ces valeurs depuis le frontmatter, jamais recalculées à la volée. Un agent qui fait un tree sur un dossier de 40 fichiers lit 40 frontmatters — quelques lignes chacun — au lieu du contenu complet de ces 40 fichiers. Économie massive de I/O et de tokens.

---

## Structure complète du file tree — Version finale de cette session

```
vault/
├── overview.md              ← jamais tronquée, 50-80 lignes, réécrit (Write)
├── profile.md               ← identité & préférences durables, édité (Edit)
├── tasks.md                 ← tâches orphelines globales, édité (Edit)
├── changelog.md             ← événements & décisions globaux, append (Edit)
├── inbox/                   ← sas de confirmation, fichiers en attente
│   └── vocal-2025-07-14.md
├── bucket/                  ← fichiers orphelins, non rattachés à un projet
│   ├── article-ai-memory.md
│   └── screenshot-review.md
│
└── projects/
    ├── startup-x/
    │   ├── description.md   ← vision & scope, réécrit si pivot (Write)
    │   ├── state.md         ← photo instantanée, édité (Edit)
    │   ├── tasks.md         ← todo vivante, édité (Edit)
    │   ├── changelog.md     ← historique + décisions unifiés, append (Edit)
    │   └── bucket/          ← fichiers propres au projet
    │       ├── vocal-meeting-client.md
    │       └── email-specs-v2.md
    │
    └── appart-search/
        ├── description.md
        ├── state.md
        ├── tasks.md
        ├── changelog.md
        └── bucket/
```

---

## Ce qui reste inchangé depuis la session précédente

Tout ce qui était tranché dans le premier brainstorming reste valide.

Les deux agents distincts avec leurs contextes mentaux différents. L'agent de maintenance se demande "est-ce que cette arborescence reflète encore la réalité ?" L'agent de search se demande "qu'est-ce que l'utilisateur a besoin de savoir ?"

Les modèles utilisés : pas chers, rapides, grand context window (120-130k). Ces tâches ne sont pas de la génération de code syntaxiquement précise, ce sont des tâches de routing, compréhension sémantique, et maintenance de connaissance.

L'overview est le premier fichier lu par les deux agents à chaque session.

L'inbox est le seul point de friction volontaire. Pas de human review systématique sur tout le reste — trop de friction, ça va à l'encontre de l'objectif.

Changelog et decisions sont unifiés en un seul fichier par projet.

Le YAML frontmatter est sur tous les fichiers. Maintenant étendu avec `tokens` et `updated` gérés automatiquement par le background job.

Tous les fichiers fréquemment édités ont un format prévisible avec des sections nommées et des ancres claires pour que les edits puissent être précis.

Le routing des données entrantes fonctionne en trois niveaux : inférence par contenu quand le signal est fort, inférence par contexte conversationnel, et question minimale avec proposition de routing quand l'ambiguïté est trop forte. L'inbox est le filet de sécurité final.

---

## Questions ouvertes — Priorisation mise à jour

Ce qui est le plus bloquant pour avancer :

Le flow end-to-end de l'agent de maintenance. Quand une requête arrive avec du texte et des fichiers, quel est l'arbre de décision exact ? Dans quel ordre l'agent lit-il les fichiers, prend-il ses décisions, et exécute-t-il ses actions ? C'est le coeur opérationnel du système et ça n'a pas encore été tracé précisément.

Les mécanismes de search. Comment l'agent de search travaille-t-il concrètement ? Est-ce du grep, du SQLite FTS, des embeddings, une combinaison ? On a les éléments structurants — frontmatter, file tree organisé, format prévisible des fichiers — mais pas la mécanique précise.

Ce qui reste ouvert mais moins urgent : la politique d'archivage des changelogs et tasks quand ils grossissent trop, l'interface (non-prioritaire sauf pour le flux inbox/notifications qui est le seul point de friction volontaire), et les intégrations MCP.

---

*Prochain point d'entrée : flow end-to-end de l'agent de maintenance — tracer précisément ce qui se passe depuis la réception d'une requête jusqu'à la mise à jour de tous les fichiers impactés.*