# Checkpoint Brainstorm — Project Manager / Knowledge Agent
*Suite de la session du 22 fév 2026 — Session 3*

---

## Ce qui a changé par rapport aux sessions précédentes

Ce document est la suite directe des deux premiers brainstormings. Tout ce qui était tranché reste tranché. Ce document capture uniquement les évolutions, nouveaux éléments, et décisions prises dans cette session. Les trois documents ensemble forment la spec complète.

---

## Décisions prises dans cette session

### 1. Le search tool est partagé entre les deux agents

Aucune distinction. Le search est un tool du système, pas du search agent. Le maintenance agent en a besoin pour vérifier si une information existe déjà avant d'écrire — "est-ce qu'on a déjà une décision sur ce sujet dans les changelogs ?" Le search agent en a besoin pour répondre aux questions. Les deux l'utilisent, les deux y ont accès.

---

### 2. BM25 remplace grep — complètement

BM25 n'est pas du grep amélioré. La différence fondamentale : grep retourne tout ce qui matche, sans classement, en correspondance exacte. BM25 tokenise, calcule la rareté de chaque terme dans le corpus (IDF), pondère par la fréquence dans le document (TF), et retourne des résultats classés par score de pertinence. Un terme rare qui apparaît dans 2 chunks sur 200 reçoit un poids énorme. Un terme omniprésent comme "projet" est quasi ignoré.

L'agent n'a plus besoin de grep. Le search tool le remplace sur tous ses cas d'usage, avec le classement en prime.

---

### 3. Le search tool — deux modes, usage distinct

Le tool `search` expose deux modes. Ce ne sont pas deux étapes d'une cascade — ce sont deux outils pour deux types de besoins différents.

**`fast`** — appelle `qmd search`, BM25 pur. Millisecondes, aucun modèle chargé. Pour les recherches par termes exacts : noms, dates, identifiants, mots-clés précis. "Comptable TVA", "Marie maquettes", "API externe".

**`deep`** — appelle `qmd query`, pipeline complet : expansion de requête, BM25, vectoriel, fusion RRF, re-ranking. Quelques secondes. Pour les questions sémantiques, les formulations vagues, les recherches conceptuelles. "Ce truc qu'on avait décidé sur l'architecture de paiement".

En pratique, `deep` sera souvent le choix par défaut parce qu'on veut de la précision. Ce n'est pas "essaie fast, si ça marche pas utilise deep" — l'agent choisit le bon mode selon la nature de la requête. Les cas d'usage exacts se raffineront avec l'expérience.

Il n'existe pas de mode hybride BM25+vectoriel sans re-ranking dans QMD. `search`, `vsearch`, `query` — trois modes natifs. On n'en expose que deux dans notre interface : fast et deep. C'est suffisant.

Un paramètre `scope` optionnel permet de cibler : `scope: "project:startup-x"` pour ne chercher que dans ce projet, `scope: "bucket"` pour les buckets uniquement. Sans scope, la search couvre tout le vault.

---

### 4. Structure des changelogs — H1 par jour, H2 par entrée

La structure de la session 1 (H2 par date, entrées en liste) est remplacée.

**Pourquoi changer :** QMD chunk aux breakpoints de score élevé. H1 = score 100, H2 = score 90. Avec l'ancienne structure, une journée dense de 10 entrées formait un chunk massif et non-discriminant. Si on cherche "abandon API externe", QMD retournait tout le jour, pas l'entrée précise.

**Nouveau format :**

```markdown
# 2025-07-14

## [décision] Abandon de l'API externe
Le prestataire ne peut pas livrer avant juin. Notre deadline est mars.
Impact : tâches d'intégration supprimées, nouvelles tâches backend créées.

## Specs reçues du client v2.1
Changements mineurs sur le module paiement. Pas d'impact planning.

## Réunion avec Marie — maquettes validées
Validées sans modification. Prêtes pour l'intégration.
```

**Pourquoi c'est mieux :**

Le H1 de date devient le chunk principal — une journée entière reste cohérente. La séquence des événements dans une journée conserve son contexte narratif : les décisions et les événements qui les ont précédées restent ensemble. Une journée normale fait 300-800 tokens. Deux semaines d'historique actif font ~2000-3000 tokens. C'est confortable dans 150k tokens de context window — on peut charger plusieurs semaines d'un coup sans stress.

QMD chipote au H2 si une journée est très dense et dépasse la taille de chunk cible. Mais il coupe entre deux entrées H2, jamais au milieu : le contenu d'une entrée reste intact.

Le tag `[décision]` reste dans le header H2. Un search BM25 sur `[décision]` retourne toutes les décisions du vault instantanément.

**Impact sur l'append :** l'agent prepend un nouveau bloc H1 en haut du fichier pour un nouveau jour. Si la journée existe déjà et qu'il faut ajouter une entrée, il peut créer un second bloc H1 pour le même jour — deux blocs H1 avec la même date dans le fichier sont acceptables, ils indiquent deux moments de mise à jour distincts. La search fonctionne pareil.

---

### 5. Structure des tasks — H1 par tâche

Même logique que les changelogs. Chaque tâche est un H1 autonome avec ses métadonnées dans le header.

```markdown
# Appeler le comptable pour TVA Q3
status: en-cours | prio: haute | ajoutée: 2025-07-14 | projet: —

Contexte : justificatifs demandés avant fin juillet.

# Valider les maquettes avec Marie
status: à-faire | prio: haute | ajoutée: 2025-07-14 | projet: startup-x
deadline: 2025-07-18
```

Chaque tâche est un chunk QMD séparé. "status: en-cours" dans le header de toutes les tâches actives permet un search BM25 instantané sur toutes les tâches en cours de tous les fichiers tasks du vault. L'agent n'a pas à lire tous les fichiers tasks manuellement.

---

### 6. Tool append — validé

Un tool `append(path, content, position: "top" | "bottom")` distinct de edit.

L'agent génère un bloc markdown complet (un H1 avec son contenu) et l'insère sans lire le fichier. Pour les changelogs : `position: "top"` — newest first. Pour d'éventuels autres usages : `position: "bottom"`.

Sur un changelog de 300 jours d'historique, l'économie est massive : sans append, l'agent lit le fichier entier pour connaître sa structure, puis edit. Avec append, il génère et insère. Zéro lecture, zéro tokens de contexte sur l'historique existant.

Le background job trigger la ré-indexation QMD sur le fichier modifié après chaque append.

---

### 7. State.md — indexé dans QMD

Les state.md de chaque projet sont indexés dans QMD.

Avec 30+ projets, "quels projets sont bloqués ?" ne peut pas reposer sur une navigation manuelle de l'agent à travers tous les projets. Un search BM25 sur "bloqué" retourne immédiatement tous les state.md qui contiennent ce terme. L'agent lit les résultats et répond.

Coût de l'indexation : les state.md sont courts par nature (photo instantanée, format structuré, sections claires). Un state.md fait rarement plus de 500 tokens. Indexer 30 state.md représente ~15k tokens d'index — insignifiant.

---

### 8. L'overview redesignée — carte structurelle, pas dashboard d'état

L'overview ne résume plus l'état opérationnel de chaque projet. C'est une carte structurelle : elle dit ce qui existe, pas comment ça va.

**Ce qu'elle contient :**
- Contexte de vie (voyage prévu, changement de situation, contrainte temporaire)
- Focus actuel — sur quoi on travaille là maintenant
- Liste de tous les projets avec leur nom et leur statut en un seul mot (actif / pause / terminé / archivé) — pas de résumé d'état, juste la liste
- Projets en pause
- Intentions pré-projet
- Count de l'inbox

**Ce qu'elle ne contient plus :**
- Résumé de l'état de chaque projet (ça vit dans state.md, cherchable via QMD)
- Décisions récentes ou highlights projet (ça vit dans les changelogs)
- Tâches en cours (ça vit dans tasks.md, cherchable via QMD)

**Quand elle est mise à jour :** uniquement quand la structure change. Nouveau projet créé, projet archivé, contexte de vie modifié. Pas à chaque mise à jour d'état d'un projet. Ça supprime le couplage fort qu'on avait : modifier startup-x ne force plus une mise à jour de l'overview.

---

### 9. Deux fichiers toujours en contexte, jamais indexés

**`overview.md`** — chargé dans le contexte des deux agents à chaque session. Jamais indexé dans QMD : il est toujours là, l'indexer serait du travail redondant.

**`tree.md`** — fichier auto-généré par le background job après chaque écriture dans le vault. Contient le tree complet du vault avec tokens, timestamps, et dossiers collapsés. Chargé dans le contexte des deux agents à chaque session. Jamais indexé dans QMD.

Le tree.md est l'outil de navigation premier de tous les agents. Ils arrivent avec la carte — ils n'ont pas à la construire.

---

### 10. Format de tree.md — riche et token-aware

Le tree.md reproduit exactement le format du tool `tree` déjà défini en session 2. Ce n'est pas un arbre de fichiers simplifié, c'est la même sortie, persistée.

```
vault/                                    [52.4k tokens]
├── overview.md                    340 tk · 2h ago
├── profile.md                     280 tk · 5d ago
├── tasks.md                       520 tk · 1d ago
├── changelog.md                 1,200 tk · 3h ago
├── inbox/                               [890 tokens]
│   └── vocal-2025-07-14.md        890 tk · 6h ago
├── bucket/                            [8.2k tokens]
│   └── ... 6 files
└── projects/                         [41.3k tokens]
    ├── startup-x/                    [18.3k tokens]
    │   └── ... 5 files, 1 folder
    └── appart-search/                [11.2k tokens]
        └── ... 5 files, 1 folder
```

Les dossiers projet sont **collapsés par défaut** dans le tree.md. Un projet contient toujours les mêmes 4 fichiers + 1 dossier bucket — la structure est répétable et connue. Pas besoin de la déplier à chaque fois. Avec 150 projets, le tree collapsé fait ~2000 tokens. Négligeable.

Le background job régénère tree.md après chaque écriture dans le vault. Les agents ont toujours la carte à jour.

---

### 11. Context window — on est généreux

Le search agent travaille dans 150k+ tokens sans problème. Il n'optimise pas compulsivement. Il charge ce qu'il faut, il répond bien. Une session typique du search agent : overview + tree.md + quelques state.md + quelques chunks de changelog + quelques bucket items = 10-15k tokens. Il reste 135k pour raisonner.

Le maintenance agent est différent — il prend des décisions d'écriture, la qualité de son contexte compte plus. Mais même lui, avec 150k tokens, a largement de quoi charger tout ce qui est pertinent pour une opération de maintenance sans stress.

---

## Ce qui est indexé QMD vs ce qui ne l'est pas

| Fichier | Indexé QMD | Raison |
|---|---|---|
| `overview.md` | ❌ | Toujours en contexte, toujours chargé |
| `tree.md` | ❌ | Toujours en contexte, auto-généré |
| `profile.md` | ❌ | Toujours en contexte, rarement modifié |
| `inbox/*` | ❌ | Temporaire, en attente de routing |
| `changelog.md` (global) | ✅ | Décisions et événements cherchables |
| `tasks.md` (global) | ✅ | Tâches cherchables par statut, sujet |
| `projects/*/description.md` | ✅ | Chercher un projet par ce qu'il fait |
| `projects/*/state.md` | ✅ | "Quels projets sont bloqués ?" |
| `projects/*/tasks.md` | ✅ | Chercher une tâche dans tous les projets |
| `projects/*/changelog.md` | ✅ | Décisions et historique cherchables |
| `bucket/*` (global) | ✅ | Découverte de contenu non-routé |
| `projects/*/bucket/*` | ✅ | Contenu projet cherchable |

---

## Structure complète du file tree — Version finale de cette session

```
vault/
├── overview.md              ← carte structurelle | jamais indexé | toujours en contexte
├── tree.md                  ← tree auto-généré | jamais indexé | toujours en contexte
├── profile.md               ← identité & préférences durables | jamais indexé
├── tasks.md                 ← tâches orphelines | H1 par tâche | indexé QMD
├── changelog.md             ← événements & décisions globaux | H1/jour H2/entrée | indexé QMD
├── inbox/                   ← sas de confirmation | jamais indexé
│   └── vocal-2025-07-14.md
├── bucket/                  ← fichiers orphelins | indexé QMD
│   ├── article-ai-memory.md
│   └── screenshot-review.md
│
└── projects/
    ├── startup-x/
    │   ├── description.md   ← vision & scope | indexé QMD
    │   ├── state.md         ← photo instantanée | indexé QMD
    │   ├── tasks.md         ← todo vivante | H1 par tâche | indexé QMD
    │   ├── changelog.md     ← historique + décisions | H1/jour H2/entrée | indexé QMD
    │   └── bucket/          ← fichiers propres au projet | indexé QMD
    │       ├── vocal-meeting-client.md
    │       └── email-specs-v2.md
    │
    └── appart-search/
        ├── description.md
        ├── state.md
        ├── tasks.md
        ├── changelog.md
        └── bucket/
```

---

## Ce qui reste inchangé depuis les sessions précédentes

Les deux agents distincts et leurs contextes mentaux. L'agent de maintenance : "est-ce que cette arborescence reflète encore la réalité ?" L'agent de search : "qu'est-ce que l'utilisateur a besoin de savoir ?"

Les tools de base : tree, read, write, edit, delete. Auxquels s'ajoute append.

Le bucket global vs par projet (session 2) — les fichiers orphelins vont dans le bucket global, les fichiers clairement liés à un projet vont directement dans le bucket du projet. Duplication si un fichier appartient à deux projets.

L'inbox comme seul point de friction volontaire. Pas de human review systématique.

Le YAML frontmatter sur tous les fichiers, avec `tokens` et `updated` gérés par le background job.

Le Claim-Confirm pattern pour les messages en queue (session 2).

Tree tool avec profondeur et metadata configurables (session 2).

Le routing à trois niveaux : inférence par contenu, inférence par contexte conversationnel, question minimale.

---

## Ce qui est maintenant tranché — Résumé express

| Sujet | Décision |
|---|---|
| Search tool | Partagé entre les deux agents |
| BM25 vs grep | BM25 remplace grep complètement |
| Modes de search | fast (BM25) et deep (pipeline complet) — cas d'usage distincts |
| Mode hybride intermédiaire | Non — deux modes suffisent |
| Scalade fast → deep | Non — l'agent choisit le bon mode selon la nature de la requête |
| Format changelog | H1 par jour, H2 par entrée |
| Format tasks | H1 par tâche |
| Tool append | Validé — position top/bottom, zéro lecture |
| State.md dans QMD | Indexé |
| Overview | Carte structurelle uniquement — pas de résumé d'état par projet |
| tree.md | Fichier séparé, auto-généré, toujours en contexte |
| Context window search agent | 150k+ confortablement, on est généreux |

---

## Questions Ouvertes — À Traiter dans des Sessions Futures

### 1. Flow End-to-End du Maintenance Agent (PRIORITÉ HAUTE)
Toujours la question la plus bloquante. Quand une requête arrive, quel est l'arbre de décision exact ? Dans quel ordre l'agent lit-il les fichiers, prend-il ses décisions, exécute-t-il ses actions ? Quel fichier touche-t-il en premier ? Comment décide-t-il si une information contredit quelque chose qui existe déjà — et utilise-t-il le search tool pour le vérifier avant d'écrire ?

### 2. Politique d'Usage Fast vs Deep
On sait que fast = BM25, deep = pipeline complet. On n'a pas défini les heuristiques concrètes que l'agent utilise pour choisir. Est-ce que c'est dans le system prompt sous forme de règles explicites ? Est-ce que l'agent décide dynamiquement ? Est-ce qu'on defaulte sur deep pour tout et on ajuste à l'usage ?

### 3. Politique d'Archivage des Changelogs et Tasks
Les fichiers vont grossir. Un changelog actif sur 2 ans peut faire 50k tokens. Questions non tranchées : à partir de quand on archive, comment (fichier `changelog-archive-2025.md` ?), qui décide (agent ou utilisateur), et les archives sont-elles indexées dans QMD ou exclues par défaut.

### 4. Interface et Flux Inbox
L'interface reste non-prioritaire sauf pour un point : l'inbox est le seul point de friction volontaire du système. Comment l'utilisateur est-il notifié qu'il y a des fichiers en attente dans l'inbox ? Comment il confirme ou corrige un routing proposé ? La mécanique de notification n'est pas définie.

### 5. MCP et Intégrations
Comment le vault est exposé via MCP pour être consommé depuis ChatGPT, Claude, ou d'autres outils. Est-ce un export markdown statique ou une API dynamique ? Comment gère-t-on l'auth si le vault est exposé sur une URL publique ?

---

*Prochain point d'entrée : flow end-to-end du maintenance agent — c'est le cœur opérationnel du système et tout le reste en dépend.*